# -*- coding: utf-8 -*-
"""FinalProjectMLDicoding_FaustaIlham.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iFMiM4Q_mla7WNg7b3qWf4Vtwhz2gVG3

<h1>
        <b><i>FINAL PROJECT MACHINE LEARNING </i></b>
        <br>
        <b><i>IMAGE CLASSIFICATION </i></b>
  </h1>
    
Project by Fausta Ilham Kharisma<br>
Email : faustailham@gmail.com
</br>


---
"""

#Import Library Tensorflow and Check Version 
import tensorflow as tf
print(tf.__version__)

#Get the datasets from url using wget command 
!wget --no-check-certificate \
  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip \
  -O /tmp/rockpaperscissors.zip

# Extract File .zip
import zipfile,os

local_zip = '/tmp/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

base_dir = '/tmp/rockpaperscissors/'
main_dir = '/tmp/rockpaperscissors/rps-cv-images/'

# check the rps-cv-image
os.listdir('/tmp/rockpaperscissors/rps-cv-images')

rock_form = os.path.join('/tmp/rockpaperscissors/rock')
paper_form = os.path.join('/tmp/rockpaperscissors/paper')
scissors_form = os.path.join('/tmp/rockpaperscissors/scissors')

rock_dir = os.listdir(rock_form)
paper_dir = os.listdir(paper_form)
scissors_dir = os.listdir(scissors_form)

print(f"Total rock pictures: {len(os.listdir(rock_form))}")
print(f"Total paper pictures: {len(os.listdir(paper_form))}")
print(f"Total scissors pictures: {len(os.listdir(scissors_form))}")

# Implement Image Augmentation
import tensorflow as tf
import keras_preprocessing
from keras_preprocessing import image
from keras_preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=40,
                    width_shift_range=0.2,
                    height_shift_range=0.2,                    
                    shear_range = 0.2,
                    horizontal_flip=True,
                    fill_mode = 'nearest',
                    validation_split = 0.4)

validation_datagen = ImageDataGenerator(
                    rescale = 1./255,
                    shear_range = 0.2,
                    zoom_range = 0.2,
                    horizontal_flip=True)

train_generator = train_datagen.flow_from_directory(
    main_dir,
    target_size=(150,150),
    batch_size=32,
	  class_mode='categorical',
    shuffle=True,
    seed=42,
    subset='training'
)

validation_generator = train_datagen.flow_from_directory(
    main_dir,
    target_size=(150,150),
    batch_size=32,
	  class_mode='categorical',
    shuffle=True,
    seed=42,
    subset='validation'
)

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(128, (3, 3), activation = 'relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(256, (3, 3), activation = 'relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation = 'relu'),
    tf.keras.layers.Dense(3, activation = 'softmax')
])

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])

# Targeting Accuracy Value 
accuracy_threshold = 95e-2
class my_callbacks(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs = None):
        if logs.get('accuracy') >= accuracy_threshold:
            print('\nIn Epoch =', epoch, '\Accuracy value has reached = %2.2f%%' %(logs['accuracy']*100), 'So, training needs to be stopped.')
            self.model.stop_training = True
        else:
          print('Accuracy must be improved')

import time
start = time.time()
history = model.fit(
    train_generator,
    steps_per_epoch = 25,
    epochs = 20,
    validation_data = validation_generator,
    validation_steps = 5,
    verbose = 2,
    callbacks = [my_callbacks()]
    )

stop = time.time()
print(f"It takes {round((stop - start)/60)} Minutes of Training Time")

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(accuracy))

plt.grid()
plt.plot(epochs, accuracy, 'r', label='Training Accuration')
plt.plot(epochs, val_accuracy, 'b', label='Validation Accuration')
plt.title('The Accuration of Training and Validation')
plt.legend(loc=0)
plt.figure()
plt.show()

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from google.colab import files
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():
 
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150,150))

  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])

  classes = model.predict(images, batch_size=10)  
  print(fn)
  
  if classes[0][0] == 1:
    print('\nidentification results = Paper')
  elif classes[0][1] == 1:
    print('\nidentification results = Rock')
  elif classes[0][2] == 1:
    print('\nidentification results =  Scissors')
  else:
    print('\nCannot be identified! Try another image!')